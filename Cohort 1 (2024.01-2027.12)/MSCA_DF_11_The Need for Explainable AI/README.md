# OVERVIEW
The base training material for this course is available in the folder Slides. 

Session Overviews

Session 01: White Box Models
Recap of interpretable models. You will gain skills in understanding how transparency is built into these models and how to interpret their outputs.

Session 02: Basic Explainability – Feature Importance, PDP, ICE
Covers foundational explainability techniques including feature importance, partial dependence plots (PDP), and individual conditional expectation (ICE). You will learn to evaluate model behavior and interpret the influence of features.

Session 03: SHAP and LIME Deep Dive
Provides a detailed exploration of SHAP and LIME, two widely used model-agnostic explanation methods. It will examine how both methods approximate local feature attributions: SHAP through axiomatic fairness and coalition-based credit distribution (with implementations like KernelSHAP and TreeSHAP), and LIME through perturbed sampling and sparse linear regression. The session will critically compare their strengths and limitations also addressing computational trade-offs, approximation quality, and implications for explainability in high-stakes domains.

Session 04: Deep Learning xAI
Focuses on explainability in the context of neural networks. You will explore techniques designed for deep models and develop skills to interpret complex architectures.

Session 05: Time-Series based xAI Methods
Introduces explainability methods tailored for sequential and time-series data. You will gain skills in understanding temporal dependencies and interpreting models used in forecasting and sequence analysis.

Session 06: Research – SAFE AI
Presents ongoing research directions in safe and responsible AI, highlighting challenges, methodologies, and open questions. You will gain insights into the state of the art and develop critical reflection skills useful for your own research.

Practical Aspects

- Each session will include hands-on practicals, where you will work on implementations.

- All practicals will be carried out using Google Colab, so you will need a Gmail account.

- We will use Google Classrooms so that each participant has their own working version of the practicals.
