{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ollama\n",
    "! pip install pandas\n",
    "! pip install matplotlib\n",
    "! ollama pull gemma3:1b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='gemma3:1b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'In which country is the city of Bern located?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ccf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-llms-ollama llama-index-embeddings-ollama pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9270d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load a PDF from ./resources, embed it with Ollama's embeddinggemma, \n",
    "# and query with Ollama's gemma3:1b.\n",
    "\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "# --- 1) Locate the PDF ---\n",
    "resources_dir = Path(\"./resources\")\n",
    "pdf_paths = sorted(glob.glob(str(resources_dir / \"*.pdf\")))\n",
    "if not pdf_paths:\n",
    "    raise FileNotFoundError(\"No PDF found in ./input. Please place one there.\")\n",
    "\n",
    "# --- 2) Configure Ollama LLM and embedding model ---\n",
    "Settings.llm = Ollama(model=\"gemma3:1b\", request_timeout=120.0)\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"embeddinggemma\")\n",
    "\n",
    "# --- 3) Load and index the PDF with embeddings ---\n",
    "docs = SimpleDirectoryReader(input_files=[pdf_paths[0]]).load_data()\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "# --- 4) Run a query ---\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "prompt = \"Build a slide for my presentation summarizing this document with a title and 3 bullet points.\"\n",
    "response = query_engine.query(prompt)\n",
    "\n",
    "print(f\"Queried file: {Path(pdf_paths[0]).name}\")\n",
    "print(\"\\n=== Response ===\\n\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d21e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b27818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe an image with Gemma3:4b via Ollama\n",
    "\n",
    "\n",
    "import ollama\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1) Path to your image ---\n",
    "image_path = \"./input/rag_simple.png\"  # <-- replace with your image\n",
    "\n",
    "# Optional: preview image in the notebook\n",
    "display(Image.open(image_path))\n",
    "\n",
    "# --- 2) Send prompt + image to Ollama ---\n",
    "response = ollama.chat(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Build a slide for my presentation summarizing this image with a title and 3 bullet points.\",\n",
    "            \"images\": [image_path],  # send the image to the model\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# --- 3) Print the description ---\n",
    "print(\"=== Image Description ===\")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
