# Courses

In this course, the fundamental concepts and advancements in natural language processing (NLP), particularly those pertaining to transformer-based architectures and large language models (LLMs), are explored in depth, leveraging insights and methodologies established in the most prominent recent literature. 

The course begins by presenting foundational principles in NLP, including traditional methods and the challenges of natural language understanding. Building on this foundation, the focus shifts to transformer models, their core concepts (e.g., self-attention, positional encodings), and how they have replaced traditional RNNs and CNNs in state-of-the-art systems. Special emphasis is placed on their architecture, pretraining mechanisms, and downstream applications, as identified in landmark works on models such as BERT, GPT, and T5. Subsequently, the focus shifts to LLMs, which are acknowledged as pivotal innovations in the field, addressing their core capabilities, challenges, and opportunities for real-world deployment.

To provide a comprehensive understanding, individual sections delve into advanced topics such as Retrieval-Augmented Generation (RAG), a state-of-the-art approach combining retrieval mechanisms with LLMs to enhance information-seeking tasks. Practical aspects of fine-tuning and lightweight experimentation are emphasized, acknowledging the constraints often associated with deploying large-scale models. Further, NLP-to-SQL systems, are explored as key applications for bridging natural language queries and structured database interactions. These systems are particularly useful for democratizing access to data for non-technical users.  

Finally, the course concludes with discussions on the explainability of LLMs, ethical considerations, and their applications in specialized domains like financial technology (FinTech), where they can revolutionize tasks such as automated reporting, fraud detection, and customer support.

While the course emphasizes conceptual understanding and lightweight experimentation, it also addresses the practical challenges of deploying and fine-tuning LLMs, particularly in resource-constrained environments. Hands-on sessions will provide participants with experience in fine-tuning smaller models, implementing simplified RAG pipelines, and building basic NLP-to-SQL systems. To this end, the course combines lectures, hands-on sessions, as well as a group project.
<img width="468" height="494" alt="image" src="https://github.com/user-attachments/assets/0c88a7da-30be-4e1a-9e91-18f6ff611406" />
